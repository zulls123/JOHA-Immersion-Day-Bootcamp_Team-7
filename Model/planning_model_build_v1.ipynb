{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABC Pharmaceuticals\n",
    "\n",
    "ABC Pharmaceuticals is embarking on a process to model the inputs and potential revenue generated from our three products given different views on the demand and costs of producing these. This code is for internal analysis of the data coming from our production facility to determine if we can build a model that will allow us to have a clear view of the feed requirements for different forward looking scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import nbformat\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "ABC Chemicals produces three primary products. To do this, they use 4 raw feed inputs into three operational units. The feed inputs are liquids and have units of measure of mega-litres (Ml), while the three primary products are measured in kilograms (kg). Each feed input is processed through a unit. Due to the type of process occurring, it is possible to also produce by-products. The past 4 years worth of data is in the excel document (Data Inputs.xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_excel(\"Data_Inputs.xlsx\")\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first analysis, let us explore the data to ensure that it is complete and usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count same number of entries for all\n",
    "print(f\"Counting rows per feature:\", input_data.count())\n",
    "\n",
    "#Check for nulls \n",
    "print(f\"Counting number of nulls per feature:\", input_data.where(input_data.isna()).count())\n",
    "\n",
    "# #Check for correct datatypes \n",
    "print(f\"DataType check:\",input_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us continue and plot out the inputs and outputs from the data frame as time series plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data[\"Timestamp\"] = pd.to_datetime(input_data[\"Timestamp\"])\n",
    "\n",
    "fig = go.Figure()\n",
    "for title in [\"Product1\", \"Product2\", \"Product3\", \"ByProduct\"]:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            mode='lines',\n",
    "            x=input_data[\"Timestamp\"],\n",
    "            y=input_data[title],\n",
    "            hoverinfo='skip',\n",
    "            name=title,\n",
    "            # line=dict(color='Black',\n",
    "            #         width=2)\n",
    "        )\n",
    "    )\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "for title in [\"Raw1\", \"ByProduct_From_1_to_2\", \"Raw2\", \"ByProduct_From_1_to_3\", \"Raw3_1\", \"Raw3_2\"]:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            mode='lines',\n",
    "            x=input_data[\"Timestamp\"],\n",
    "            y=input_data[title],\n",
    "            hoverinfo='skip',\n",
    "            name=title,\n",
    "            # line=dict(color='Black',\n",
    "            #         width=2)\n",
    "        )\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's go through each of the unit operations and see how the input data corresponds to the output from the unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit 1\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        mode='markers',\n",
    "        x=input_data[\"Raw1\"],\n",
    "        y=input_data[\"Product1\"],\n",
    "        hoverinfo='skip',\n",
    "        name=\"Product1\",\n",
    "        # line=dict(color='Black',\n",
    "        #         width=2)\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        mode='markers',\n",
    "        x=input_data[\"Raw1\"],\n",
    "        y=input_data[\"ByProduct\"],\n",
    "        hoverinfo='skip',\n",
    "        name=\"ByProduct\",\n",
    "        # line=dict(color='Black',\n",
    "        #         width=2)\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout({'title': \"Byprodut and Product1 from Unit 1 as a function of Feed Raw1\",\n",
    "                   \"xaxis\": {'title': \"Raw1 (Ml)\"},\n",
    "                   \"yaxis\": {'title': \"Product1 (kg), Byproduct (Ml)\"}})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, unit 2. Unit 2 receives 2 inputs and therefore we need to consider each of them to see what the relationship might be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Replicate analysis above for unit 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally for unit3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Replicate analysis above for unit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for completeness, let us do a correlation matrix as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Plot a correlation heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Before we start cleaning the data, we will split the data into the inputs and outputs for each unit operation. We will also add the timestamp as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_1 = input_data[[\"Raw1\", \"ByProduct\", \"Product1\"]]\n",
    "unit_1.index = input_data[\"Timestamp\"]\n",
    "unit_2 = input_data[[\"ByProduct_From_1_to_2\", \"Raw2\", \"Product2\"]]\n",
    "unit_2.index = input_data[\"Timestamp\"]\n",
    "unit_3 = input_data[[\"ByProduct_From_1_to_3\", \"Raw3_1\", \"Raw3_2\", \"Product3\"]]\n",
    "unit_3.index = input_data[\"Timestamp\"]\n",
    "\n",
    "#Checking output\n",
    "unit_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to clean the data before testing any models. An external source has provided code that can be used to do this. The function is is the helper_code file, and is called mahalanobis_outlier_removal. We have not yet had time to implement this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Implement the mahalanobis_outlier_removal function\n",
    "#clean_unit1 = mahalanobis_outlier_removal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Model Building\n",
    "\n",
    "We need to create training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: split the data into train and test datasets. For now we don't need to consider an out of time or validation dataset\n",
    "# unit_1_train, unit_1_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a model for each of the four units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: train the four models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the models that we have built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Evaluate MSE, MAE, R2, MAPE and RMSE for each of the models, also get parity plots and residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build a final version of the model that is built with all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Build and save final models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Model Build\n",
    "\n",
    "The next step in the process is to build a model for the whole of the plant. This will take as inputs, the feed rates of the 4 raw feeds, as well as the fraction of byproduct that is directed to each of unit2 and unit3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plant(plant_input: pd.DataFrame):\n",
    "    # TO DO:\n",
    "    # Update code to allow the byproduct to have an excess stream as well.\n",
    "\n",
    "    plant_input[\"byproduct_to_unit2\"] = plant_input[\"byproduct_to_unit2\"]/(plant_input[\"byproduct_to_unit2\"] + plant_input[\"byproduct_to_unit3\"])\n",
    "    plant_input[\"byproduct_to_unit3\"] = plant_input[\"byproduct_to_unit3\"]/(plant_input[\"byproduct_to_unit2\"] + plant_input[\"byproduct_to_unit3\"])\n",
    "\n",
    "    # plant_input : 6 input feeds, and 2 values for the percentages of each feed that goes to unit 2 and 3\n",
    "    reg_product1 = joblib.load(\"unit_models/{}.joblib\".format(\"product_1\"))\n",
    "    reg_byproduct = joblib.load(\"unit_models/{}.joblib\".format(\"byproduct\"))\n",
    "    reg_product2 = joblib.load(\"unit_models/{}.joblib\".format(\"product_2\"))\n",
    "    reg_product3 = joblib.load(\"unit_models/{}.joblib\".format(\"product_3\"))\n",
    "\n",
    "    product1 = reg_product1.predict(plant_input[[\"Raw1\"]]).reshape([len(plant_input[[\"Raw1\"]]),])\n",
    "    byproduct = reg_byproduct.predict(plant_input[[\"Raw1\"]])\n",
    "\n",
    "    plant_input[\"byproduct\"] = byproduct\n",
    "    plant_input[\"ByProduct_From_1_to_2\"] = plant_input[\"byproduct\"]*plant_input[\"byproduct_to_unit2\"]\n",
    "    plant_input[\"ByProduct_From_1_to_3\"] = plant_input[\"byproduct\"]*plant_input[\"byproduct_to_unit3\"]\n",
    "\n",
    "\n",
    "    product2 = reg_product2.predict(plant_input[[\"ByProduct_From_1_to_2\", \"Raw2\"]])\n",
    "    product3 = reg_product3.predict(plant_input[[\"ByProduct_From_1_to_3\", \"Raw3_1\", \"Raw3_2\"]])\n",
    "\n",
    "    return product1, product2, product3, plant_input[\"byproduct\"] - plant_input[\"ByProduct_From_1_to_2\"] - plant_input[\"ByProduct_From_1_to_3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Optimization\n",
    "\n",
    "Now we need to define the objective function to use for the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(product1, product2, product3, byproduct,\n",
    "                       product_sell_prices, product_demand, unmet_demand_penalty,\n",
    "                       storage_costs, discard_costs, detailed=False):\n",
    "    \n",
    "    # TO DO: Build out the objective function required for the optimization\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to build the optimizer. Based on prior experience, the differential evolution algorithm has been selected for the optimizer, however, this is not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(\n",
    "        bounds, \n",
    "        opt_params, \n",
    "        PRODUCT_SELL_PRICE, \n",
    "        PRODUCT_DEMAND, \n",
    "        PRODUCT_UNMET_DEMAND_PENALTY,\n",
    "        PRODUCT_STORAGE_COST, \n",
    "        PRODUCT_DISCARD_COST\n",
    "        ):\n",
    "    \n",
    "    def model(X_in):\n",
    "        if len(X_in.shape) == 1:\n",
    "            X_in = X_in.reshape([1,6])\n",
    "        X_in = pd.DataFrame(X_in, columns=[\"Raw1\",\"Raw2\",\"Raw3_1\",\"Raw3_2\",\"byproduct_to_unit2\",\"byproduct_to_unit3\"])\n",
    "        if np.isnan(X_in.iloc[0,0]):\n",
    "            return np.nan\n",
    "        product1, product2, product3, byproduct = plant(X_in)\n",
    "\n",
    "        objective = objective_function(product1, product2, product3, byproduct,\n",
    "                       PRODUCT_SELL_PRICE, PRODUCT_DEMAND, PRODUCT_UNMET_DEMAND_PENALTY,\n",
    "                       PRODUCT_STORAGE_COST, PRODUCT_DISCARD_COST)\n",
    "        return objective.iloc[0]\n",
    "\n",
    "    result = differential_evolution(model, bounds=bounds, **opt_params)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Output\n",
    "\n",
    "We need to capture the outputs from all the scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisaction and Analysis\n",
    "\n",
    "Let us get some visualisations of the outputs, or else get pretty printed versions that compare the outputs of the different scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "immersion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
